{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain Change Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and import relevant libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#Import dataframe libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Import models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute graded precision, recall and f-measure\n",
    "\n",
    "def precision_recall_f_compute(predictions, y_test):\n",
    "    fn=0\n",
    "    fp=0\n",
    "    tp=0\n",
    "    for pred, real in zip(predictions, y_test):\n",
    "        if pred == real:\n",
    "            tp = tp + 1\n",
    "        elif pred < real:\n",
    "            fn = fn + 1\n",
    "            #fn = fn + (real - pred)\n",
    "        elif pred > real:\n",
    "            fp = fp + 1\n",
    "            #fp = fp + (pred - real)\n",
    "    precision = float(tp)/float((fp+tp))\n",
    "    recall = float(tp)/(float(fn+tp))\n",
    "    f = 2.0*precision*recall/(precision+recall)\n",
    "\n",
    "    return precision, recall, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424 entries, 0 to 423\n",
      "Data columns (total 3 columns):\n",
      "Pain_Relevance    424 non-null object\n",
      "Pain_Change       287 non-null object\n",
      "Raw_Text          400 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>Patient. Arrived to VDH for pain management an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>Patient will continue on pain control regimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>Patient will continue to take pain medications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient received from CHC via wheelchair on ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>Patient remains in 8-10/10 pain. PCA initiated.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pain_Relevance Pain_Change  \\\n",
       "0            yes    increase   \n",
       "1            yes    not sure   \n",
       "2            yes    not sure   \n",
       "3             no         NaN   \n",
       "4            yes    increase   \n",
       "\n",
       "                                            Raw_Text  \n",
       "0  Patient. Arrived to VDH for pain management an...  \n",
       "1  Patient will continue on pain control regimen ...  \n",
       "2  Patient will continue to take pain medications...  \n",
       "3  Patient received from CHC via wheelchair on ro...  \n",
       "4   Patient remains in 8-10/10 pain. PCA initiated.   "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store patient data in file\n",
    "file = 'patient_data1.xlsx'\n",
    "\n",
    "#Store patient data in Pandas dataframe\n",
    "data = pd.read_excel(file)\n",
    "data.columns = ['Pain_Relevance', 'Pain_Change', 'Raw_Text'] #Rename columns\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pain relevant data points:  391\n",
      "Number of pain irrelevant data points:  33\n",
      "Patient. Arrived to VDH for pain management and IVF while awaiting admission. Pain was 7/10 on arrival in chest bilaterally as documented. Patient. Somewhat anxious as portrayed by irregular breathing pattern with talking however able to tolerate eating. All VSS including pulse ox at 100% on room air. Patient. Given oral valium and IV pain meds. Patient. Appears more calm after valium administration. Will transfer to 5100 via wheelchair with mother at side. ACRN\n"
     ]
    }
   ],
   "source": [
    "#Display number of values for pain relevance and pain irrelevance\n",
    "print(\"Number of pain relevant data points: \", (data['Pain_Relevance'] == 'yes').sum())\n",
    "print(\"Number of pain irrelevant data points: \", (data['Pain_Relevance'] == 'no').sum())\n",
    "print(data['Raw_Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280 entries, 0 to 422\n",
      "Data columns (total 3 columns):\n",
      "Pain_Relevance    280 non-null object\n",
      "Pain_Change       280 non-null object\n",
      "Raw_Text          280 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 8.8+ KB\n",
      "Pain relevant data points with no null values:  280\n"
     ]
    }
   ],
   "source": [
    "#Change newline character(s) in Pain Change column to \"not sure\"\n",
    "data.loc[data['Pain_Change'] == '\\n', 'Pain_Change'] = 'not sure'\n",
    "\n",
    "#Change null Pain Change values where Pain Relevance is true to \"not sure\"\n",
    "data.loc[(data['Pain_Relevance'] == 'yes') & (data['Pain_Change'] == np.NaN), 'Pain_Change'] = 'not sure'\n",
    "\n",
    "#Drop rows with null Pain Relevance or null Raw Text fields\n",
    "data = data.dropna(subset=['Pain_Relevance', 'Raw_Text', 'Pain_Change'])\n",
    "data.info()\n",
    "data.head()\n",
    "print(\"Pain relevant data points with no null values: \", (data['Pain_Relevance'] == 'yes').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes']\n",
      "yes    280\n",
      "Name: Pain_Relevance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print unique values in Pain Relevance column\n",
    "print(pd.unique(data['Pain_Relevance']))\n",
    "print(data['Pain_Relevance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['increase' 'not sure' 'decrease' 'no change']\n",
      "decrease     145\n",
      "increase      51\n",
      "no change     51\n",
      "not sure      33\n",
      "Name: Pain_Change, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print unique values in Pain Change column\n",
    "print(pd.unique(data['Pain_Change']))\n",
    "print(data['Pain_Change'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "      <td>decrease</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pain_Relevance Pain_Change  \\\n",
       "0            yes    increase   \n",
       "1            yes    not sure   \n",
       "2            yes    not sure   \n",
       "4            yes    increase   \n",
       "5            yes    decrease   \n",
       "\n",
       "                                            Raw_Text  \n",
       "0  patient . arrived vdh pain management ivf awai...  \n",
       "1  patient continue pain control regimen 0/10 pain .  \n",
       "2  patient continue take pain medication without ...  \n",
       "4     patient remains 8-10/10 pain . pca initiated .  \n",
       "5  patient continues rate pain 8/10 morphine pca ...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change text to lower case, remove stop words and punctuation\n",
    "data['Raw_Text'] = data['Raw_Text'].str.lower()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "#ps = PorterStemmer()\n",
    "ps = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(row):\n",
    "    text = row['Raw_Text']\n",
    "    #print(text) #Test statement\n",
    "    meaningful_words = [w for w in nltk.tokenize.word_tokenize(text) if not w in stop_words]  \n",
    "    #print(\" \".join(meaningful_words)) #Test statement\n",
    "    \n",
    "    proc_words = []\n",
    "    for w in meaningful_words:\n",
    "        #proc_words.append(ps.stem(w))\n",
    "        proc_words.append(ps.lemmatize(w))\n",
    "    #print(\" \".join(proc_words)) #Test statement\n",
    "    return \" \".join(proc_words)\n",
    "\n",
    "data['Raw_Text'] = data.apply(preprocess, axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "      <th>Str_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "      <td>decrease</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "      <td>no change</td>\n",
       "      <td>pain remains 8/10 overnight pt appeared comfor...</td>\n",
       "      <td>pain remains 8/10 overnight pt appeared comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>continuous setting increased , patient continu...</td>\n",
       "      <td>continuous setting increased , patient continu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient pain increased 8/10 9/10 chest . reach...</td>\n",
       "      <td>patient pain increased 8/10 9/10 chest . reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "      <td>decrease</td>\n",
       "      <td>patient report feel like `` getting better .</td>\n",
       "      <td>patient report feel like `` getting better .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yes</td>\n",
       "      <td>decrease</td>\n",
       "      <td>patient denies pain shift .</td>\n",
       "      <td>patient denies pain shift .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pain_Relevance Pain_Change  \\\n",
       "0             yes    increase   \n",
       "1             yes    not sure   \n",
       "2             yes    not sure   \n",
       "4             yes    increase   \n",
       "5             yes    decrease   \n",
       "6             yes   no change   \n",
       "7             yes    increase   \n",
       "8             yes    increase   \n",
       "9             yes    decrease   \n",
       "10            yes    decrease   \n",
       "\n",
       "                                             Raw_Text  \\\n",
       "0   patient . arrived vdh pain management ivf awai...   \n",
       "1   patient continue pain control regimen 0/10 pain .   \n",
       "2   patient continue take pain medication without ...   \n",
       "4      patient remains 8-10/10 pain . pca initiated .   \n",
       "5   patient continues rate pain 8/10 morphine pca ...   \n",
       "6   pain remains 8/10 overnight pt appeared comfor...   \n",
       "7   continuous setting increased , patient continu...   \n",
       "8   patient pain increased 8/10 9/10 chest . reach...   \n",
       "9        patient report feel like `` getting better .   \n",
       "10                        patient denies pain shift .   \n",
       "\n",
       "                                             Str_Text  \n",
       "0   patient . arrived vdh pain management ivf awai...  \n",
       "1   patient continue pain control regimen 0/10 pain .  \n",
       "2   patient continue take pain medication without ...  \n",
       "4      patient remains 8-10/10 pain . pca initiated .  \n",
       "5   patient continues rate pain 8/10 morphine pca ...  \n",
       "6   pain remains 8/10 overnight pt appeared comfor...  \n",
       "7   continuous setting increased , patient continu...  \n",
       "8   patient pain increased 8/10 9/10 chest . reach...  \n",
       "9        patient report feel like `` getting better .  \n",
       "10                        patient denies pain shift .  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to string type\n",
    "data['Str_Text'] = data.Raw_Text.astype(str) \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoded_pain = list()\n",
    "score = 0\n",
    "for i,row in data.iterrows():\n",
    "    if row[1] == 'decrease':\n",
    "        score = 0\n",
    "    elif row[1] == 'no change':\n",
    "        score = 1\n",
    "    elif row[1] == 'not sure':\n",
    "        score = 2\n",
    "    elif row[1] == 'increase':\n",
    "        score = 3\n",
    "    encoded_pain.append(score)\n",
    "\n",
    "data['Pain_Change'] = encoded_pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "      <th>Str_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>pain remains 8/10 overnight pt appeared comfor...</td>\n",
       "      <td>pain remains 8/10 overnight pt appeared comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous setting increased , patient continu...</td>\n",
       "      <td>continuous setting increased , patient continu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>patient pain increased 8/10 9/10 chest . reach...</td>\n",
       "      <td>patient pain increased 8/10 9/10 chest . reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>patient report feel like `` getting better .</td>\n",
       "      <td>patient report feel like `` getting better .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>patient denies pain shift .</td>\n",
       "      <td>patient denies pain shift .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pain_Relevance  Pain_Change  \\\n",
       "0             yes            3   \n",
       "1             yes            2   \n",
       "2             yes            2   \n",
       "4             yes            3   \n",
       "5             yes            0   \n",
       "6             yes            1   \n",
       "7             yes            3   \n",
       "8             yes            3   \n",
       "9             yes            0   \n",
       "10            yes            0   \n",
       "\n",
       "                                             Raw_Text  \\\n",
       "0   patient . arrived vdh pain management ivf awai...   \n",
       "1   patient continue pain control regimen 0/10 pain .   \n",
       "2   patient continue take pain medication without ...   \n",
       "4      patient remains 8-10/10 pain . pca initiated .   \n",
       "5   patient continues rate pain 8/10 morphine pca ...   \n",
       "6   pain remains 8/10 overnight pt appeared comfor...   \n",
       "7   continuous setting increased , patient continu...   \n",
       "8   patient pain increased 8/10 9/10 chest . reach...   \n",
       "9        patient report feel like `` getting better .   \n",
       "10                        patient denies pain shift .   \n",
       "\n",
       "                                             Str_Text  \n",
       "0   patient . arrived vdh pain management ivf awai...  \n",
       "1   patient continue pain control regimen 0/10 pain .  \n",
       "2   patient continue take pain medication without ...  \n",
       "4      patient remains 8-10/10 pain . pca initiated .  \n",
       "5   patient continues rate pain 8/10 morphine pca ...  \n",
       "6   pain remains 8/10 overnight pt appeared comfor...  \n",
       "7   continuous setting increased , patient continu...  \n",
       "8   patient pain increased 8/10 9/10 chest . reach...  \n",
       "9        patient report feel like `` getting better .  \n",
       "10                        patient denies pain shift .  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_pain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "      <th>Str_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "      <td>patient continues rate pain 8/10 morphine pca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>pain remains 8/10 overnight pt appeared comfor...</td>\n",
       "      <td>pain remains 8/10 overnight pt appeared comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>continuous setting increased , patient continu...</td>\n",
       "      <td>continuous setting increased , patient continu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>patient pain increased 8/10 9/10 chest . reach...</td>\n",
       "      <td>patient pain increased 8/10 9/10 chest . reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>patient report feel like `` getting better .</td>\n",
       "      <td>patient report feel like `` getting better .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>patient denies pain shift .</td>\n",
       "      <td>patient denies pain shift .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pain_Relevance  Pain_Change  \\\n",
       "0             yes            3   \n",
       "1             yes            2   \n",
       "2             yes            2   \n",
       "4             yes            3   \n",
       "5             yes            0   \n",
       "6             yes            1   \n",
       "7             yes            3   \n",
       "8             yes            3   \n",
       "9             yes            0   \n",
       "10            yes            0   \n",
       "\n",
       "                                             Raw_Text  \\\n",
       "0   patient . arrived vdh pain management ivf awai...   \n",
       "1   patient continue pain control regimen 0/10 pain .   \n",
       "2   patient continue take pain medication without ...   \n",
       "4      patient remains 8-10/10 pain . pca initiated .   \n",
       "5   patient continues rate pain 8/10 morphine pca ...   \n",
       "6   pain remains 8/10 overnight pt appeared comfor...   \n",
       "7   continuous setting increased , patient continu...   \n",
       "8   patient pain increased 8/10 9/10 chest . reach...   \n",
       "9        patient report feel like `` getting better .   \n",
       "10                        patient denies pain shift .   \n",
       "\n",
       "                                             Str_Text  \n",
       "0   patient . arrived vdh pain management ivf awai...  \n",
       "1   patient continue pain control regimen 0/10 pain .  \n",
       "2   patient continue take pain medication without ...  \n",
       "4      patient remains 8-10/10 pain . pca initiated .  \n",
       "5   patient continues rate pain 8/10 morphine pca ...  \n",
       "6   pain remains 8/10 overnight pt appeared comfor...  \n",
       "7   continuous setting increased , patient continu...  \n",
       "8   patient pain increased 8/10 9/10 chest . reach...  \n",
       "9        patient report feel like `` getting better .  \n",
       "10                        patient denies pain shift .  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 10)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation and vectorize text\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv_n1 = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "cv_n2 = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,2),tokenizer = token.tokenize)\n",
    "cv_n3 = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,3),tokenizer = token.tokenize)\n",
    "vectorized_data_n1 = cv_n1.fit_transform(data['Str_Text'].copy())\n",
    "vectorized_data_n2 = cv_n2.fit_transform(data['Str_Text'].copy())\n",
    "vectorized_data_n3 = cv_n3.fit_transform(data['Str_Text'].copy())\n",
    "\n",
    "#encoder = LabelEncoder()\n",
    "#data['Pain_Change'] = encoder.fit_transform(data['Pain_Change'].astype(str))\n",
    "\n",
    "#Assign labels\n",
    "y = data[['Pain_Change']]\n",
    "y = np.ravel(y)\n",
    "\n",
    "#Select k best features\n",
    "kx1 = SelectKBest(chi2, k=10)\n",
    "kx2 = SelectKBest(chi2, k=10)\n",
    "kx3 = SelectKBest(chi2, k=10)\n",
    "\n",
    "#Get k best features and assign to feature vectors\n",
    "x1 = kx1.fit_transform(vectorized_data_n1, y)\n",
    "x2 = kx2.fit_transform(vectorized_data_n2, y)\n",
    "x3 = kx3.fit_transform(vectorized_data_n3, y)\n",
    "\n",
    "x1.shape\n",
    "x2.shape\n",
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all features for each n-gram model\n",
    "feature_names_n1 = cv_n1.get_feature_names()\n",
    "bow_features_n1 = pd.DataFrame(vectorized_data_n1.toarray(), columns = feature_names_n1)\n",
    "#print(bow_features_n1)\n",
    "\n",
    "feature_names_n2 = cv_n2.get_feature_names()\n",
    "bow_features_n2 = pd.DataFrame(vectorized_data_n2.toarray(), columns = feature_names_n2)\n",
    "#print(bow_features_n2)\n",
    "\n",
    "feature_names_n3 = cv_n3.get_feature_names()\n",
    "bow_features_n3 = pd.DataFrame(vectorized_data_n3.toarray(), columns = feature_names_n3)\n",
    "#print(bow_features_n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show k-best features for each n-gram model\n",
    "\n",
    "mask = kx1.get_support(indices=True)\n",
    "new_features1 = bow_features_n1.columns[mask]\n",
    "#print(new_features1)\n",
    "\n",
    "mask = kx2.get_support(indices=True)\n",
    "new_features2 = bow_features_n2.columns[mask]\n",
    "#print(new_features2)\n",
    "\n",
    "mask = kx3.get_support(indices=True)\n",
    "new_features3 = bow_features_n3.columns[mask]\n",
    "#print(new_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigram features:  (196, 10)\n",
      "Number of bigram features:  (196, 10)\n",
      "Number of trigram features:  (196, 10)\n"
     ]
    }
   ],
   "source": [
    "#Set test ratio and get training and testing sets\n",
    "test_ratio = 0.3\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y, test_size=test_ratio, shuffle=True, random_state=1)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y, test_size=test_ratio, shuffle=True, random_state=1)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y, test_size=test_ratio, shuffle=True, random_state=1)\n",
    "\n",
    "print(\"Number of unigram features: \", x1_train.shape)\n",
    "print(\"Number of bigram features: \", x2_train.shape)\n",
    "print(\"Number of trigram features: \", x3_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8055555555555556, 0.5918367346938775, 0.6823529411764706)\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate neural network model---Ordinal classification\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000, random_state=42)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000)\n",
    "mlp = mlp.fit(x1_train, y1_train)\n",
    "train_pred = mlp.predict(x1_train)\n",
    "test_pred = mlp.predict(x1_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using MLP\n",
    "print(precision_recall_f_compute(test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7692307692307693, 0.6382978723404256, 0.6976744186046512)\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate neural network model---Ordinal classification\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=10000, random_state=42)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000)\n",
    "mlp = mlp.fit(x1_train, y1_train)\n",
    "train_pred = mlp.predict(x1_train)\n",
    "test_pred = mlp.predict(x1_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using MLP\n",
    "print(precision_recall_f_compute(test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7837837837837838, 0.6041666666666666, 0.6823529411764706)\n"
     ]
    }
   ],
   "source": [
    "#Train evaluate an ordinal logistic classification model\n",
    "#Train a Logistic Regression Classifier\n",
    "param_grid_lr = {\n",
    "         'C': [1.0, 1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "         'solver': ('newton-cg', 'lbfgs', 'sag', 'saga')\n",
    "          }\n",
    "lr = GridSearchCV(LogisticRegression(random_state=42, multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "#lr = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "lr = lr.fit(x1_train, y1_train)\n",
    "lr_train_pred = lr.predict(x1_train)\n",
    "lr_test_pred = lr.predict(x1_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using MLP\n",
    "print(precision_recall_f_compute(lr_test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8378378378378378, 0.62, 0.7126436781609196)\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree classifier for ordinal classification\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "#dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(x1_train, y1_train)\n",
    "dt_train_pred = dt.predict(x1_train)\n",
    "dt_test_pred = dt.predict(x1_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using decision tree\n",
    "print(precision_recall_f_compute(dt_test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8484848484848485, 0.5490196078431373, 0.6666666666666667)\n"
     ]
    }
   ],
   "source": [
    "#Train a Random Forest Classifier---Ordinal classification\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "#rf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rf = rf.fit(x1_train, y1_train)\n",
    "rf_train_pred = rf.predict(x1_train)\n",
    "rf_test_pred = rf.predict(x1_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using decision trees\n",
    "print(precision_recall_f_compute(rf_test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LDA topics as features to ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/amanuel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Working with LDA topics as features to ML\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import pickle\n",
    "import gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "#import spacy\n",
    "import pandas as pd\n",
    "import nltk; nltk.download('stopwords')\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import re\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['come','order','try','go','get','make','drink','plate','dish','restaurant','place',\n",
    "                  'would','really','like','great','service','came','got'])\n",
    "\n",
    "\n",
    "def strip_newline(series):\n",
    "    return [str(review).replace('\\n','') for review in series]\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "    \n",
    "def get_corpus(df):\n",
    "    df['text'] = strip_newline(df.text)\n",
    "    words = list(sent_to_words(df.text))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[review] for review in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    return corpus, id2word, bigram\n",
    "\n",
    "rev_train = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_train = rev_train.rename(columns={\"Str_Text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus4, train_id2word4, bigram_train4 = get_corpus(rev_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train4 = gensim.models.ldamulticore.LdaMulticore(\n",
    "                           corpus=train_corpus4,\n",
    "                           num_topics=2,\n",
    "                           id2word=train_id2word4,\n",
    "                           chunksize=100,\n",
    "                           workers=7, # Num. Processing Cores - 1\n",
    "                           passes=50,\n",
    "                           eval_every = 1,\n",
    "                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.184*\"pca\" + 0.150*\"cope_supported\" + 0.089*\"shift\" + 0.070*\"collaborate\" + 0.069*\"continues\" + 0.067*\"dose\" + 0.054*\"chest\" + 0.050*\"demand\" + 0.050*\"remains\" + 0.044*\"rate\"'),\n",
       " (1,\n",
       "  '0.145*\"medication\" + 0.081*\"intervention\" + 0.081*\"see_emar\" + 0.081*\"satisfied\" + 0.064*\"knowledge_deficit\" + 0.063*\"state_carry\" + 0.063*\"method\" + 0.062*\"met_continue\" + 0.052*\"regarding\" + 0.051*\"knowledge\"')]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train4.print_topics(2,num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(rev_train)):\n",
    "    top_topics = lda_train4.get_document_topics(train_corpus4[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(2)]\n",
    "    #topic_vec.extend([rev_train.iloc[i].count()]) # counts of notes\n",
    "    topic_vec.extend([len(rev_train.iloc[i].text)]) # length of notes\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5, 49]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_array = csr_matrix(x1, dtype=np.int8).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cumulative = list()\n",
    "for i,j in zip(x1_array,X):\n",
    "    X_cumulative.append(np.concatenate((i, j), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cum_train, x_cum_test, y1_train, y1_test = train_test_split(X_cumulative, y, test_size=test_ratio, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 0 0 0 2 0 0 1 0 2 1 3 1 3 0 0 3 2 1 1 0 3 0 0 0 2 1 0 1 3 1 3 0 0 0 1\n",
      " 0 3 3 0 1 1 0 0 0 1 3 0 2 0 2 0 3 0 2 1 0 3 1 2 1 0 0 1 1 2 1 2 0 2 3 2 2\n",
      " 0 0 0 0 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For bigram based analysis\n",
    "x2_array = csr_matrix(x2, dtype=np.int8).toarray()\n",
    "\n",
    "X_cumulative = list()\n",
    "for i,j in zip(x2_array,X):\n",
    "    X_cumulative.append(np.concatenate((i, j), axis=0))\n",
    "\n",
    "x_cum_train, x_cum_test, y2_train, y2_test = train_test_split(X_cumulative, y, test_size=test_ratio, shuffle=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train evaluate a Logistic Regression Classifier for concatenated n-grams and lda topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7547169811320755, 0.5633802816901409, 0.6451612903225807)\n"
     ]
    }
   ],
   "source": [
    "#Train evaluate a Logistic Regression Classifier for concatenated n-grams and lda topics as features\n",
    "param_grid_lr = {\n",
    "         'C': [1.0, 1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "         'solver': ('newton-cg', 'lbfgs', 'sag', 'saga')\n",
    "          }\n",
    "lr = GridSearchCV(LogisticRegression(random_state=42, multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "#lr = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "lr = lr.fit(x_cum_train, y1_train)\n",
    "lr_train_pred = lr.predict(x_cum_train)\n",
    "lr_test_pred = lr.predict(x_cum_test)\n",
    "\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using logistic regression\n",
    "print(precision_recall_f_compute(lr_test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train evaluate a Decision Tree Classifier for concatenated n-grams and lda topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6551724137931034, 0.59375, 0.6229508196721311)\n"
     ]
    }
   ],
   "source": [
    "#Train evaluate a Decision Tree Classifier for concatenated n-grams and lda topics as features\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "#dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(x_cum_train, y1_train)\n",
    "dt_train_pred = dt.predict(x_cum_train)\n",
    "dt_test_pred = dt.predict(x_cum_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using decision tree\n",
    "print(precision_recall_f_compute(dt_test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train evaluate a Random Forest for concatenated n-grams and lda topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8444444444444444, 0.4935064935064935, 0.6229508196721312)\n"
     ]
    }
   ],
   "source": [
    "#Train evaluate a Random Forest for concatenated n-grams and lda topics as features\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "#rf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rf = rf.fit(x_cum_train, y2_train)\n",
    "rf_train_pred = rf.predict(x_cum_train)\n",
    "rf_test_pred = rf.predict(x_cum_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using random forest\n",
    "print(precision_recall_f_compute(rf_test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train evaluate a Feedforward Network for concatenated n-grams and lda topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8222222222222222, 0.4868421052631579, 0.6115702479338843)\n"
     ]
    }
   ],
   "source": [
    "#Train evaluate a Feedforward Network for concatenated n-grams and lda topics as features\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000, random_state=42)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000)\n",
    "mlp = mlp.fit(x_cum_train, y1_train)\n",
    "train_pred = mlp.predict(x_cum_train)\n",
    "test_pred = mlp.predict(x_cum_test)\n",
    "\n",
    "#evaluate PRF for Ordinal Classification using random forest\n",
    "print(precision_recall_f_compute(test_pred, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with ML models using only lda topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traing ML models with lda topics as features\n",
    "encoder = LabelEncoder()\n",
    "rev_train['Pain_Change'] = encoder.fit_transform(data['Pain_Change'].astype(str))\n",
    "\n",
    "#y = data[['Pain_Relevance']]\n",
    "y = np.array(rev_train.Pain_Change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lda features as input for ordinal classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.592 +- 0.083\n",
      "Logisitic Regression SGD Val f1: 0.380 +- 0.097\n",
      "Decision Tree Val f1: 0.693 +- 0.076\n",
      "MLP Val f1: 0.693 +- 0.076\n",
      "Random Forest Val f1: 0.678 +- 0.074\n",
      "\n",
      "\n",
      "Logistic Regression Val precision: 0.648 +- 0.110\n",
      "Logisitic Regression SGD Val precision: 0.323 +- 0.111\n",
      "Decision Tree Val precision: 0.717 +- 0.058\n",
      "MLP Val precision: 0.717 +- 0.058\n",
      "Random Forest Val precision: 0.987 +- 0.016\n",
      "\n",
      "\n",
      "Logistic Regression Val recall: 0.553 +- 0.091\n",
      "Logisitic Regression SGD Val recall: 0.494 +- 0.080\n",
      "Decision Tree Val recall: 0.674 +- 0.104\n",
      "MLP Val recall: 0.674 +- 0.104\n",
      "Random Forest Val recall: 0.522 +- 0.081\n"
     ]
    }
   ],
   "source": [
    "#lda features as input for ordinal classification\n",
    "\n",
    "classes = ['decrease','no change', 'not sure', 'increase']\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1, cv_dt_f1, cv_mlp_f1, cv_rf_f1  = [], [], [], [], [], []\n",
    "cv_lr_precision, cv_lrsgd_precision, cv_svcsgd_precision, cv_dt_precision, cv_mlp_precision, cv_rf_precision = [], [], [], [],[], []\n",
    "cv_lr_recall, cv_lrsgd_recall, cv_svcsgd_recall, cv_dt_recall, cv_mlp_recall, cv_rf_recall = [], [], [], [],[], []\n",
    "\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    \n",
    "    \n",
    "    cv_lr_f1.append(precision_recall_f_compute(y_pred, y_val)[2])\n",
    "    cv_lr_precision.append(precision_recall_f_compute(y_pred, y_val)[0])\n",
    "    cv_lr_recall.append(precision_recall_f_compute(y_pred, y_val)[1])\n",
    "    \n",
    "    \n",
    "    # Logistic Regression Mini-Batch SGD\n",
    "    sgd = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    \n",
    "    cv_lrsgd_f1.append(precision_recall_f_compute(y_pred, y_val)[2])\n",
    "    cv_lrsgd_precision.append(precision_recall_f_compute(y_pred, y_val)[0])\n",
    "    cv_lrsgd_recall.append(precision_recall_f_compute(y_pred, y_val)[1])\n",
    "    \n",
    "    # Decision tree classifier\n",
    "    dt = DecisionTreeClassifier(random_state=42).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = dt.predict(X_val_scale)\n",
    "    #cv_dt_f1.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "    #cv_dt_precision.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "    #cv_dt_recall.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "    \n",
    "    \n",
    "    cv_dt_f1.append(precision_recall_f_compute(y_pred, y_val)[2])\n",
    "    cv_dt_precision.append(precision_recall_f_compute(y_pred, y_val)[0])\n",
    "    cv_dt_recall.append(precision_recall_f_compute(y_pred, y_val)[1])\n",
    "    \n",
    "    \n",
    "    # MLP Classifier\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(50,50), max_iter=10000, random_state=42).fit(X_train_scale, y_train)\n",
    "    y_pred = dt.predict(X_val_scale)\n",
    "    #cv_mlp_f1.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "    #cv_mlp_precision.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "    #cv_mlp_recall.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "    \n",
    "    cv_mlp_f1.append(precision_recall_f_compute(y_pred, y_val)[2])\n",
    "    cv_mlp_precision.append(precision_recall_f_compute(y_pred, y_val)[0])\n",
    "    cv_mlp_recall.append(precision_recall_f_compute(y_pred, y_val)[1])\n",
    "    \n",
    "    \n",
    "    #Random Forest Classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_val_scale)\n",
    "    #cv_rf_f1.append(f1_score(y_val, y_pred, average='weighted'))\n",
    "    #cv_rf_precision.append(precision_score(y_val, y_pred, average='weighted'))\n",
    "    #cv_rf_recall.append(recall_score(y_val, y_pred, average='weighted'))\n",
    "    \n",
    "    cv_rf_f1.append(precision_recall_f_compute(y_pred, y_val)[2])\n",
    "    cv_rf_precision.append(precision_recall_f_compute(y_pred, y_val)[0])\n",
    "    cv_rf_recall.append(precision_recall_f_compute(y_pred, y_val)[1])\n",
    "    \n",
    "\n",
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
    "#print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')\n",
    "print(f'Decision Tree Val f1: {np.mean(cv_dt_f1):.3f} +- {np.std(cv_dt_f1):.3f}')\n",
    "print(f'MLP Val f1: {np.mean(cv_mlp_f1):.3f} +- {np.std(cv_mlp_f1):.3f}')\n",
    "print(f'Random Forest Val f1: {np.mean(cv_rf_f1):.3f} +- {np.std(cv_rf_f1):.3f}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(f'Logistic Regression Val precision: {np.mean(cv_lr_precision):.3f} +- {np.std(cv_lr_precision):.3f}')\n",
    "print(f'Logisitic Regression SGD Val precision: {np.mean(cv_lrsgd_precision):.3f} +- {np.std(cv_lrsgd_precision):.3f}')\n",
    "#print(f'SVM Huber Val precision: {np.mean(cv_svcsgd_precision):.3f} +- {np.std(cv_svcsgd_precision):.3f}')\n",
    "print(f'Decision Tree Val precision: {np.mean(cv_dt_precision):.3f} +- {np.std(cv_dt_precision):.3f}')\n",
    "print(f'MLP Val precision: {np.mean(cv_mlp_precision):.3f} +- {np.std(cv_mlp_precision):.3f}')\n",
    "print(f'Random Forest Val precision: {np.mean(cv_rf_precision):.3f} +- {np.std(cv_rf_precision):.3f}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Logistic Regression Val recall: {np.mean(cv_lr_recall):.3f} +- {np.std(cv_lr_recall):.3f}')\n",
    "print(f'Logisitic Regression SGD Val recall: {np.mean(cv_lrsgd_recall):.3f} +- {np.std(cv_lrsgd_recall):.3f}')\n",
    "#print(f'SVM Huber Val recall: {np.mean(cv_svcsgd_recall):.3f} +- {np.std(cv_svcsgd_recall):.3f}')\n",
    "print(f'Decision Tree Val recall: {np.mean(cv_dt_recall):.3f} +- {np.std(cv_dt_recall):.3f}')\n",
    "print(f'MLP Val recall: {np.mean(cv_mlp_recall):.3f} +- {np.std(cv_mlp_recall):.3f}')\n",
    "print(f'Random Forest Val recall: {np.mean(cv_rf_recall):.3f} +- {np.std(cv_rf_recall):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
