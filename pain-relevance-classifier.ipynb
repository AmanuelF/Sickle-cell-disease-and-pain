{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain Relevance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and import relevant libraries\n",
    "\n",
    "import nltk\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#Import dataframe libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Import models\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampled_data_smote(X, y):\n",
    "    return SMOTE(sampling_strategy='auto', random_state=42).fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 424 entries, 0 to 423\n",
      "Data columns (total 3 columns):\n",
      "Pain_Relevance    424 non-null object\n",
      "Pain_Change       287 non-null object\n",
      "Raw_Text          400 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>Patient. Arrived to VDH for pain management an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>Patient will continue on pain control regimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>Patient will continue to take pain medications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient received from CHC via wheelchair on ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>Patient remains in 8-10/10 pain. PCA initiated.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pain_Relevance Pain_Change  \\\n",
       "0            yes    increase   \n",
       "1            yes    not sure   \n",
       "2            yes    not sure   \n",
       "3             no         NaN   \n",
       "4            yes    increase   \n",
       "\n",
       "                                            Raw_Text  \n",
       "0  Patient. Arrived to VDH for pain management an...  \n",
       "1  Patient will continue on pain control regimen ...  \n",
       "2  Patient will continue to take pain medications...  \n",
       "3  Patient received from CHC via wheelchair on ro...  \n",
       "4   Patient remains in 8-10/10 pain. PCA initiated.   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store patient data in file\n",
    "file = 'patient_data1.xlsx'\n",
    "\n",
    "#Store patient data in Pandas dataframe\n",
    "data = pd.read_excel(file)\n",
    "data.columns = ['Pain_Relevance', 'Pain_Change', 'Raw_Text'] #Rename columns\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pain relevant data points:  391\n",
      "Number of pain irrelevant data points:  33\n",
      "Patient. Arrived to VDH for pain management and IVF while awaiting admission. Pain was 7/10 on arrival in chest bilaterally as documented. Patient. Somewhat anxious as portrayed by irregular breathing pattern with talking however able to tolerate eating. All VSS including pulse ox at 100% on room air. Patient. Given oral valium and IV pain meds. Patient. Appears more calm after valium administration. Will transfer to 5100 via wheelchair with mother at side. ACRN\n"
     ]
    }
   ],
   "source": [
    "#Display number of values for pain relevance and pain irrelevance\n",
    "print(\"Number of pain relevant data points: \", (data['Pain_Relevance'] == 'yes').sum())\n",
    "print(\"Number of pain irrelevant data points: \", (data['Pain_Relevance'] == 'no').sum())\n",
    "print(data['Raw_Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400 entries, 0 to 423\n",
      "Data columns (total 3 columns):\n",
      "Pain_Relevance    400 non-null object\n",
      "Pain_Change       280 non-null object\n",
      "Raw_Text          400 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.5+ KB\n",
      "Pain relevant data points with no null values:  382\n"
     ]
    }
   ],
   "source": [
    "#Change newline character(s) in Pain Change column to \"not sure\"\n",
    "data.loc[data['Pain_Change'] == '\\n', 'Pain_Change'] = 'not sure'\n",
    "\n",
    "#Change null Pain Change values where Pain Relevance is true to \"not sure\"\n",
    "data.loc[(data['Pain_Relevance'] == 'yes') & (data['Pain_Change'] == np.NaN), 'Pain_Change'] = 'not sure'\n",
    "\n",
    "#Drop rows with null Pain Relevance or null Raw Text fields\n",
    "data = data.dropna(subset=['Pain_Relevance', 'Raw_Text'])\n",
    "data.info()\n",
    "data.head()\n",
    "print(\"Pain relevant data points with no null values: \", (data['Pain_Relevance'] == 'yes').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>Patient. Arrived to VDH for pain management an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>Patient will continue on pain control regimen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>Patient will continue to take pain medications...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patient received from CHC via wheelchair on ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>Patient remains in 8-10/10 pain. PCA initiated.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pain_Relevance Pain_Change  \\\n",
       "0            yes    increase   \n",
       "1            yes    not sure   \n",
       "2            yes    not sure   \n",
       "3             no         NaN   \n",
       "4            yes    increase   \n",
       "\n",
       "                                            Raw_Text  \n",
       "0  Patient. Arrived to VDH for pain management an...  \n",
       "1  Patient will continue on pain control regimen ...  \n",
       "2  Patient will continue to take pain medications...  \n",
       "3  Patient received from CHC via wheelchair on ro...  \n",
       "4   Patient remains in 8-10/10 pain. PCA initiated.   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes' 'no']\n",
      "yes    382\n",
      "no      18\n",
      "Name: Pain_Relevance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print unique values in Pain Relevance column\n",
    "print(pd.unique(data['Pain_Relevance']))\n",
    "print(data['Pain_Relevance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['increase' 'not sure' nan 'decrease' 'no change']\n",
      "decrease     145\n",
      "increase      51\n",
      "no change     51\n",
      "not sure      33\n",
      "Name: Pain_Change, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Print unique values in Pain Change column\n",
    "print(pd.unique(data['Pain_Change']))\n",
    "print(data['Pain_Change'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient received chc via wheelchair room air ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pain_Relevance Pain_Change  \\\n",
       "0            yes    increase   \n",
       "1            yes    not sure   \n",
       "2            yes    not sure   \n",
       "3             no         NaN   \n",
       "4            yes    increase   \n",
       "\n",
       "                                            Raw_Text  \n",
       "0  patient . arrived vdh pain management ivf awai...  \n",
       "1  patient continue pain control regimen 0/10 pain .  \n",
       "2  patient continue take pain medication without ...  \n",
       "3  patient received chc via wheelchair room air ....  \n",
       "4     patient remains 8-10/10 pain . pca initiated .  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change text to lower case, remove stopwords and punctuation\n",
    "data['Raw_Text'] = data['Raw_Text'].str.lower()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "lem = WordNetLemmatizer()\n",
    "#ps = PorterStemmer()\n",
    "\n",
    "def preprocess(row):\n",
    "    text = row['Raw_Text']\n",
    "    #print(text) #Test statement\n",
    "    meaningful_words = [w for w in nltk.tokenize.word_tokenize(text) if not w in stop_words]  \n",
    "    #print(\" \".join(meaningful_words)) #Test statement\n",
    "    \n",
    "    proc_words = []\n",
    "    for w in meaningful_words:\n",
    "        proc_words.append(lem.lemmatize(w))\n",
    "        #proc_words.append(ps.stem(w))\n",
    "    #print(\" \".join(proc_words)) #Test statement\n",
    "    return \" \".join(proc_words)\n",
    "\n",
    "data['Raw_Text'] = data.apply(preprocess, axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "      <th>Str_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient received chc via wheelchair room air ....</td>\n",
       "      <td>patient received chc via wheelchair room air ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pain_Relevance Pain_Change  \\\n",
       "0            yes    increase   \n",
       "1            yes    not sure   \n",
       "2            yes    not sure   \n",
       "3             no         NaN   \n",
       "4            yes    increase   \n",
       "\n",
       "                                            Raw_Text  \\\n",
       "0  patient . arrived vdh pain management ivf awai...   \n",
       "1  patient continue pain control regimen 0/10 pain .   \n",
       "2  patient continue take pain medication without ...   \n",
       "3  patient received chc via wheelchair room air ....   \n",
       "4     patient remains 8-10/10 pain . pca initiated .   \n",
       "\n",
       "                                            Str_Text  \n",
       "0  patient . arrived vdh pain management ivf awai...  \n",
       "1  patient continue pain control regimen 0/10 pain .  \n",
       "2  patient continue take pain medication without ...  \n",
       "3  patient received chc via wheelchair room air ....  \n",
       "4     patient remains 8-10/10 pain . pca initiated .  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Str_Text'] = data.Raw_Text.astype(str) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation and vectorize text\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv_n1 = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "cv_n2 = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,2),tokenizer = token.tokenize)\n",
    "cv_n3 = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,3),tokenizer = token.tokenize)\n",
    "vectorized_data_n1 = cv_n1.fit_transform(data['Str_Text'].copy())\n",
    "vectorized_data_n2 = cv_n2.fit_transform(data['Str_Text'].copy())\n",
    "vectorized_data_n3 = cv_n3.fit_transform(data['Str_Text'].copy())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['Pain_Relevance'] = encoder.fit_transform(data['Pain_Relevance'].astype(str))\n",
    "\n",
    "y = data[['Pain_Relevance']]\n",
    "y = np.ravel(y)\n",
    "\n",
    "#Select k best features\n",
    "#Select k best features\n",
    "kx1 = SelectKBest(chi2, k=10)\n",
    "kx2 = SelectKBest(chi2, k=10)\n",
    "kx3 = SelectKBest(chi2, k=10)\n",
    "\n",
    "\n",
    "x1 = kx1.fit_transform(vectorized_data_n1, y)\n",
    "x2 = kx2.fit_transform(vectorized_data_n2, y)\n",
    "x3 = kx3.fit_transform(vectorized_data_n3, y)\n",
    "\n",
    "x1.shape\n",
    "x2.shape\n",
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigram features:  (280, 10)\n",
      "Number of bigram features:  (280, 10)\n",
      "Number of trigram features:  (280, 10)\n"
     ]
    }
   ],
   "source": [
    "#Set test ratio and get training and testing sets\n",
    "test_ratio = 0.3\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y, test_size=test_ratio, shuffle=True, random_state=1)\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y, test_size=test_ratio, shuffle=True, random_state=1)\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y, test_size=test_ratio, shuffle=True, random_state=1)\n",
    "\n",
    "print(\"Number of unigram features: \", x1_train.shape)\n",
    "print(\"Number of bigram features: \", x2_train.shape)\n",
    "print(\"Number of trigram features: \", x3_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, y1_train = get_sampled_data_smote(x1_train, y1_train)\n",
    "x2_train, y2_train = get_sampled_data_smote(x2_train, y2_train)\n",
    "x3_train, y3_train = get_sampled_data_smote(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all features for each n-gram model\n",
    "feature_names_n1 = cv_n1.get_feature_names()\n",
    "bow_features_n1 = pd.DataFrame(vectorized_data_n1.toarray(), columns = feature_names_n1)\n",
    "#print(bow_features_n1)\n",
    "\n",
    "feature_names_n2 = cv_n2.get_feature_names()\n",
    "bow_features_n2 = pd.DataFrame(vectorized_data_n2.toarray(), columns = feature_names_n2)\n",
    "#print(bow_features_n2)\n",
    "\n",
    "feature_names_n3 = cv_n3.get_feature_names()\n",
    "bow_features_n3 = pd.DataFrame(vectorized_data_n3.toarray(), columns = feature_names_n3)\n",
    "#print(bow_features_n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ability', 'admission', 'discharge', 'goal', 'home', 'note', 'outcome',\n",
      "       'pain', 'progressing', 'respiratory'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Show k-best features for each n-gram model\n",
    "mask = kx1.get_support(indices=True)\n",
    "new_features1 = bow_features_n1.columns[mask]\n",
    "print(new_features1)\n",
    "\n",
    "mask = kx2.get_support(indices=True)\n",
    "new_features2 = bow_features_n2.columns[mask]\n",
    "#print(new_features2)\n",
    "\n",
    "mask = kx3.get_support(indices=True)\n",
    "new_features3 = bow_features_n3.columns[mask]\n",
    "#print(new_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Unigram Performance on Test Set:\n",
      "Macro Precision Score: 0.688\n",
      "Weighted Precision Score: 0.969\n",
      "Macro Recall Score: 0.956\n",
      "Weighted Recall Score: 0.917\n",
      "Micro F1 Score: 0.917\n",
      "Macro F1 Score: 0.750\n",
      "Weighted F1 Score: 0.934\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [ 10 104]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmlp = mlp.fit(x2_train, y2_train)\\ntrain_pred = mlp.predict(x2_train)\\ntest_pred = mlp.predict(x2_test)\\n\\nprint('Neural Network Bigram Performance on Training Set:')\\nprint('Parameters: ', mlp.get_params)\\nprint('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, train_pred))\\nprint('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, train_pred, average='macro'))\\nprint('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, train_pred, average='weighted'))\\nprint('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, train_pred, average='macro'))\\nprint('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, train_pred, average='weighted'))\\nprint('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='micro'))\\nprint('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='macro'))\\nprint('Weighted F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='weighted'))\\n#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\\nprint('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, train_pred))\\n\\nprint()\\n\\nprint('Neural Network Bigram Performance on Testing Set:')\\nprint('Parameters: ', mlp.get_params)\\nprint('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, test_pred))\\nprint('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, test_pred, average='macro'))\\nprint('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, test_pred, average='weighted'))\\nprint('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, test_pred, average='macro'))\\nprint('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, test_pred, average='weighted'))\\nprint('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='micro'))\\nprint('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='macro'))\\nprint('Weighted F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='weighted'))\\n#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\\nprint('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, test_pred))\\n\\nprint()\\n\\n\\nmlp = mlp.fit(x3_train, y3_train)\\ntrain_pred = mlp.predict(x3_train)\\ntest_pred = mlp.predict(x3_test)\\n\\nprint('Neural Network Trigram Performance on Training Set:')\\nprint('Parameters: ', mlp.get_params)\\nprint('Accuracy Score: %.3f' % metrics.accuracy_score(y3_train, train_pred))\\nprint('Macro Precision Score: %.3f' % metrics.precision_score(y3_train, train_pred, average='macro'))\\nprint('Weighted Precision Score: %.3f' % metrics.precision_score(y3_train, train_pred, average='weighted'))\\nprint('Macro Recall Score: %.3f' % metrics.recall_score(y3_train, train_pred, average='macro'))\\nprint('Weighted Recall Score: %.3f' % metrics.recall_score(y3_train, train_pred, average='weighted'))\\nprint('Micro F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='micro'))\\nprint('Macro F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='macro'))\\nprint('Weighted F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='weighted'))\\n#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\\nprint('Confusion Matrix: \\n', metrics.confusion_matrix(y3_train, train_pred))\\n\\nprint()\\n\\nprint('Neural Network Trigram Performance on Testing Set:')\\nprint('Parameters: ', mlp.get_params)\\nprint('Accuracy Score: %.3f' % metrics.accuracy_score(y3_test, test_pred))\\nprint('Macro Precision Score: %.3f' % metrics.precision_score(y3_test, test_pred, average='macro'))\\nprint('Weighted Precision Score: %.3f' % metrics.precision_score(y3_test, test_pred, average='weighted'))\\nprint('Macro Recall Score: %.3f' % metrics.recall_score(y3_test, test_pred, average='macro'))\\nprint('Weighted Recall Score: %.3f' % metrics.recall_score(y3_test, test_pred, average='weighted'))\\nprint('Micro F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='micro'))\\nprint('Macro F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='macro'))\\nprint('Weighted F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='weighted'))\\n#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\\nprint('Confusion Matrix: \\n', metrics.confusion_matrix(y3_test, test_pred))\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and evaluate neural network model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000, random_state=42)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000)\n",
    "mlp = mlp.fit(x1_train, y1_train)\n",
    "train_pred = mlp.predict(x1_train)\n",
    "test_pred = mlp.predict(x1_test)\n",
    "\n",
    "'''\n",
    "print('Neural Network Unigram Performance on Training Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_train, train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_train, train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_train, train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_train, train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_train, train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_train, train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_train, train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_train, train_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_train, train_pred))\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#print()\n",
    "\n",
    "print('Neural Network Unigram Performance on Test Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, test_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "'''\n",
    "mlp = mlp.fit(x2_train, y2_train)\n",
    "train_pred = mlp.predict(x2_train)\n",
    "test_pred = mlp.predict(x2_test)\n",
    "\n",
    "print('Neural Network Bigram Performance on Training Set:')\n",
    "print('Parameters: ', mlp.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Neural Network Bigram Performance on Testing Set:')\n",
    "print('Parameters: ', mlp.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "mlp = mlp.fit(x3_train, y3_train)\n",
    "train_pred = mlp.predict(x3_train)\n",
    "test_pred = mlp.predict(x3_test)\n",
    "\n",
    "print('Neural Network Trigram Performance on Training Set:')\n",
    "print('Parameters: ', mlp.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_train, train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_train, train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_train, train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_train, train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_train, train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_train, train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Neural Network Trigram Performance on Testing Set:')\n",
    "print('Parameters: ', mlp.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_test, test_pred))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Performance on Testing Set:\n",
      "Macro Precision Score: 0.688\n",
      "Weighted Precision Score: 0.969\n",
      "Macro Recall Score: 0.956\n",
      "Weighted Recall Score: 0.917\n",
      "Micro F1 Score: 0.917\n",
      "Macro F1 Score: 0.750\n",
      "Weighted F1 Score: 0.934\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [ 10 104]]\n",
      "Neural Network Bigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.688\n",
      "Weighted Precision Score: 0.969\n",
      "Macro Recall Score: 0.956\n",
      "Weighted Recall Score: 0.917\n",
      "Micro F1 Score: 0.917\n",
      "Macro F1 Score: 0.750\n",
      "Weighted F1 Score: 0.934\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [ 10 104]]\n",
      "\n",
      "Neural Network Trigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.688\n",
      "Weighted Precision Score: 0.969\n",
      "Macro Recall Score: 0.956\n",
      "Weighted Recall Score: 0.917\n",
      "Micro F1 Score: 0.917\n",
      "Macro F1 Score: 0.750\n",
      "Weighted F1 Score: 0.934\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [ 10 104]]\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate neural network model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=10000, random_state=42)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=10000)\n",
    "mlp = mlp.fit(x1_train, y1_train)\n",
    "train_pred = mlp.predict(x1_train)\n",
    "test_pred = mlp.predict(x1_test)\n",
    "\n",
    "'''\n",
    "print('Neural Network Performance on Training Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_train, train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_train, train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_train, train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_train, train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_train, train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_train, train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_train, train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_train, train_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_train, train_pred))\n",
    "\n",
    "'''\n",
    "#print()\n",
    "\n",
    "print('Neural Network Performance on Testing Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, test_pred))\n",
    "\n",
    "'''\n",
    "print()\n",
    "\n",
    "mlp = mlp.fit(x2_train, y2_train)\n",
    "train_pred = mlp.predict(x2_train)\n",
    "test_pred = mlp.predict(x2_test)\n",
    "\n",
    "print('Neural Network Bigram Performance on Training Set:')\n",
    "print('Parameters: ', mlp.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_train, train_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, train_pred))\n",
    "\n",
    "print()\n",
    "'''\n",
    "print('Neural Network Bigram Performance on Testing Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "mlp = mlp.fit(x3_train, y3_train)\n",
    "predictions = mlp.predict(x3_test)\n",
    "\n",
    "'''\n",
    "print('Neural Network Trigram Performance on Training Set:')\n",
    "print('Parameters: ', mlp.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_train, train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_train, train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_train, train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_train, train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_train, train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_train, train_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_train, train_pred))\n",
    "\n",
    "print()\n",
    "'''\n",
    "print('Neural Network Trigram Performance on Testing Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance on Testing Set:\n",
      "Macro Precision Score: 0.731\n",
      "Weighted Precision Score: 0.973\n",
      "Macro Recall Score: 0.969\n",
      "Weighted Recall Score: 0.942\n",
      "Micro F1 Score: 0.942\n",
      "Macro F1 Score: 0.800\n",
      "Weighted F1 Score: 0.951\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [  7 107]]\n",
      "Decision Tree Bigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.731\n",
      "Weighted Precision Score: 0.973\n",
      "Macro Recall Score: 0.969\n",
      "Weighted Recall Score: 0.942\n",
      "Micro F1 Score: 0.942\n",
      "Macro F1 Score: 0.800\n",
      "Weighted F1 Score: 0.951\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [  7 107]]\n"
     ]
    }
   ],
   "source": [
    "#Train a Decision Tree Classifier on the data, make predictions, and evaluate\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "#dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(x1_train, y1_train)\n",
    "dt_train_pred = dt.predict(x1_train)\n",
    "dt_test_pred = dt.predict(x1_test)\n",
    "\n",
    "'''\n",
    "print(\"Decision Tree Performance on Training Set:\")\n",
    "print(\"Parameters: \", dt.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_train, dt_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_train, dt_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_train, dt_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_train, dt_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_train, dt_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_train, dt_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_train, dt_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_train, dt_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_train, dt_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Decision Tree Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", dt.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, dt_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, dt_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, dt_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, dt_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, dt_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, dt_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, dt_test_pred))\n",
    "\n",
    "\n",
    "'''\n",
    "print()\n",
    "\n",
    "dt = dt.fit(x2_train, y2_train)\n",
    "dt_train_pred = dt.predict(x2_train)\n",
    "dt_test_pred = dt.predict(x2_test)\n",
    "\n",
    "print(\"Decision Tree Bigram Performance on Training Set:\")\n",
    "print(\"Parameters: \", dt.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, dt_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, dt_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, dt_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, dt_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, dt_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, dt_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, dt_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_train, dt_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, dt_train_pred))\n",
    "\n",
    "print()\n",
    "'''\n",
    "print(\"Decision Tree Bigram Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", dt.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, dt_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, dt_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, dt_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, dt_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, dt_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_test, dt_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, dt_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance on Training Set:\n",
      "Parameters:  <bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=1e-09)>\n",
      "Accuracy Score: 0.927\n",
      "Macro Precision Score: 0.927\n",
      "Weighted Precision Score: 0.927\n",
      "Macro Recall Score: 0.927\n",
      "Weighted Recall Score: 0.927\n",
      "Micro F1 Score: 0.927\n",
      "Macro F1 Score: 0.927\n",
      "Confusion Matrix: \n",
      " [[251  17]\n",
      " [ 22 246]]\n",
      "\n",
      "Naive Bayes Performance on Testing Set:\n",
      "Parameters:  <bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=1e-09)>\n",
      "Accuracy Score: 0.892\n",
      "Macro Precision Score: 0.658\n",
      "Weighted Precision Score: 0.966\n",
      "Macro Recall Score: 0.943\n",
      "Weighted Recall Score: 0.892\n",
      "Micro F1 Score: 0.892\n",
      "Macro F1 Score: 0.710\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [ 13 101]]\n",
      "\n",
      "Naive Bayes Bigram Performance on Training Set:\n",
      "Parameters:  <bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=1e-09)>\n",
      "Accuracy Score: 0.612\n",
      "Macro Precision Score: 0.746\n",
      "Weighted Precision Score: 0.746\n",
      "Macro Recall Score: 0.612\n",
      "Weighted Recall Score: 0.612\n",
      "Micro F1 Score: 0.612\n",
      "Macro F1 Score: 0.551\n",
      "Confusion Matrix: \n",
      " [[ 65 203]\n",
      " [  5 263]]\n",
      "\n",
      "Naive Bayes Bigram Performance on Testing Set:\n",
      "Parameters:  <bound method BaseEstimator.get_params of GaussianNB(priors=None, var_smoothing=1e-09)>\n",
      "Accuracy Score: 0.950\n",
      "Macro Precision Score: 0.737\n",
      "Weighted Precision Score: 0.950\n",
      "Macro Recall Score: 0.737\n",
      "Weighted Recall Score: 0.950\n",
      "Micro F1 Score: 0.950\n",
      "Macro F1 Score: 0.737\n",
      "Confusion Matrix: \n",
      " [[  3   3]\n",
      " [  3 111]]\n"
     ]
    }
   ],
   "source": [
    "#Train a Naive Bayes Classifier on the data, make predictions, and evaluate\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(x1_train.toarray(), y1_train)\n",
    "gnb_train_pred = gnb.predict(x1_train.toarray())\n",
    "gnb_test_pred = gnb.predict(x1_test.toarray())\n",
    "\n",
    "print(\"Naive Bayes Performance on Training Set:\")\n",
    "print(\"Parameters: \", gnb.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_train, gnb_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_train, gnb_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_train, gnb_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_train, gnb_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_train, gnb_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_train, gnb_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_train, gnb_train_pred, average='macro'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_train, gnb_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Naive Bayes Performance on Testing Set:\")\n",
    "print(\"Parameters: \", gnb.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, gnb_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, gnb_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, gnb_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, gnb_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, gnb_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, gnb_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, gnb_test_pred, average='macro'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, gnb_test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "gnb = gnb.fit(x2_train.toarray(), y2_train)\n",
    "gnb_train_pred = gnb.predict(x2_train.toarray())\n",
    "gnb_test_pred = gnb.predict(x2_test.toarray())\n",
    "\n",
    "print(\"Naive Bayes Bigram Performance on Training Set:\")\n",
    "print(\"Parameters: \", gnb.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, gnb_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, gnb_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, gnb_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, gnb_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, gnb_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, gnb_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, gnb_train_pred, average='macro'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, gnb_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Naive Bayes Bigram Performance on Testing Set:\")\n",
    "print(\"Parameters: \", gnb.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, gnb_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, gnb_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, gnb_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, gnb_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, gnb_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, gnb_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, gnb_test_pred, average='macro'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, gnb_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance on Testing Set:\n",
      "Macro Precision Score: 0.625\n",
      "Weighted Precision Score: 0.963\n",
      "Macro Recall Score: 0.921\n",
      "Weighted Recall Score: 0.850\n",
      "Micro F1 Score: 0.850\n",
      "Macro F1 Score: 0.657\n",
      "Weighted F1 Score: 0.889\n",
      "Confusion Matrix: \n",
      " [[ 6  0]\n",
      " [18 96]]\n",
      "\n",
      "Logistic Regression Bigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.625\n",
      "Weighted Precision Score: 0.963\n",
      "Macro Recall Score: 0.921\n",
      "Weighted Recall Score: 0.850\n",
      "Micro F1 Score: 0.850\n",
      "Macro F1 Score: 0.657\n",
      "Weighted F1 Score: 0.889\n",
      "Confusion Matrix: \n",
      " [[ 6  0]\n",
      " [18 96]]\n",
      "\n",
      "Logistic Regression Trigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.625\n",
      "Weighted Precision Score: 0.963\n",
      "Macro Recall Score: 0.921\n",
      "Weighted Recall Score: 0.850\n",
      "Micro F1 Score: 0.850\n",
      "Macro F1 Score: 0.657\n",
      "Weighted F1 Score: 0.889\n",
      "Confusion Matrix: \n",
      " [[ 6  0]\n",
      " [18 96]]\n"
     ]
    }
   ],
   "source": [
    "#Train a Logistic Regression Classifier\n",
    "param_grid_lr = {\n",
    "         'C': [1.0, 1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "         'solver': ('newton-cg', 'lbfgs', 'sag', 'saga')\n",
    "          }\n",
    "lr = GridSearchCV(LogisticRegression(random_state=42, multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "#lr = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "lr = lr.fit(x1_train, y1_train)\n",
    "lr_train_pred = lr.predict(x1_train)\n",
    "lr_test_pred = lr.predict(x1_test)\n",
    "\n",
    "'''\n",
    "print(\"Logistic Regression Performance on Training Set:\")\n",
    "print(\"Parameters: \", lr.best_params_)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_train, lr_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_train, lr_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_train, lr_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_train, lr_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_train, lr_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_train, lr_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_train, lr_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_train, lr_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_train, lr_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Logistic Regression Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", lr.best_params_)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, lr_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, lr_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, lr_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, lr_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, lr_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, lr_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, lr_test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "lr = lr.fit(x2_train, y2_train)\n",
    "lr_train_pred = lr.predict(x2_train)\n",
    "lr_test_pred = lr.predict(x2_test)\n",
    "\n",
    "'''\n",
    "print(\"Logistic Regression Bigram Performance on Training Set:\")\n",
    "print(\"Parameters: \", lr.best_params_)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, lr_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, lr_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, lr_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, lr_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, lr_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, lr_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, lr_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_train, lr_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, lr_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Logistic Regression Bigram Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", lr.best_params_)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, lr_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, lr_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, lr_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, lr_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, lr_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_test, lr_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, lr_test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "lr = lr.fit(x3_train, y3_train)\n",
    "lr_train_pred = lr.predict(x3_train)\n",
    "lr_test_pred = lr.predict(x3_test)\n",
    "\n",
    "'''\n",
    "print(\"Logistic Regression Trigram Performance on Training Set:\")\n",
    "print(\"Parameters: \", lr.best_params_)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_train, lr_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_train, lr_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_train, lr_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_train, lr_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_train, lr_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_train, lr_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_train, lr_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_train, lr_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_train, lr_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Logistic Regression Trigram Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", lr.best_params_)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_test, lr_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_test, lr_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_test, lr_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_test, lr_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_test, lr_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_test, lr_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_test, lr_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance on Testing Set:\n",
      "Macro Precision Score: 0.603\n",
      "Weighted Precision Score: 0.960\n",
      "Macro Recall Score: 0.899\n",
      "Weighted Recall Score: 0.808\n",
      "Micro F1 Score: 0.808\n",
      "Macro F1 Score: 0.615\n",
      "Weighted F1 Score: 0.861\n",
      "Confusion Matrix: \n",
      " [[ 6  0]\n",
      " [23 91]]\n",
      "\n",
      "Random Forest Bigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.594\n",
      "Weighted Precision Score: 0.959\n",
      "Macro Recall Score: 0.886\n",
      "Weighted Recall Score: 0.783\n",
      "Micro F1 Score: 0.783\n",
      "Macro F1 Score: 0.594\n",
      "Weighted F1 Score: 0.844\n",
      "Confusion Matrix: \n",
      " [[ 6  0]\n",
      " [26 88]]\n",
      "\n",
      "Random Forest Trigram Performance on Testing Set:\n",
      "Macro Precision Score: 0.594\n",
      "Weighted Precision Score: 0.959\n",
      "Macro Recall Score: 0.886\n",
      "Weighted Recall Score: 0.783\n",
      "Micro F1 Score: 0.783\n",
      "Macro F1 Score: 0.594\n",
      "Weighted F1 Score: 0.844\n",
      "Confusion Matrix: \n",
      " [[ 6  0]\n",
      " [26 88]]\n"
     ]
    }
   ],
   "source": [
    "#Train a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "#rf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rf = rf.fit(x1_train, y1_train)\n",
    "rf_train_pred = rf.predict(x1_train)\n",
    "rf_test_pred = rf.predict(x1_test)\n",
    "\n",
    "'''\n",
    "print(\"Random Forest Performance on Training Set:\")\n",
    "print(\"Paramters: \", rf.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_train, rf_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_train, rf_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_train, rf_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_train, rf_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_train, rf_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_train, rf_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_train, rf_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_train, rf_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_train, rf_train_pred))\n",
    "\n",
    "'''\n",
    "\n",
    "#print()\n",
    "\n",
    "print(\"Random Forest Performance on Testing Set:\")\n",
    "#print(\"Paramters: \", rf.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, rf_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, rf_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, rf_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, rf_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, rf_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, rf_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, rf_test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "rf = rf.fit(x2_train, y2_train)\n",
    "rf_train_pred = rf.predict(x2_train)\n",
    "rf_test_pred = rf.predict(x2_test)\n",
    "\n",
    "'''\n",
    "print(\"Random Forest Bigram Performance on Training Set:\")\n",
    "print(\"Paramters: \", rf.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_train, rf_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_train, rf_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_train, rf_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_train, rf_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_train, rf_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_train, rf_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_train, rf_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_train, rf_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_train, rf_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Random Forest Bigram Performance on Testing Set:\")\n",
    "#print(\"Paramters: \", rf.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y2_test, rf_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y2_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, rf_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, rf_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y2_test, rf_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y2_test, rf_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y2_test, rf_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y2_test, rf_test_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "rf = rf.fit(x3_train, y3_train)\n",
    "rf_train_pred = rf.predict(x3_train)\n",
    "rf_test_pred = rf.predict(x3_test)\n",
    "\n",
    "'''\n",
    "print(\"Random Forest Trigram Performance on Training Set:\")\n",
    "print(\"Paramters: \", rf.get_params)\n",
    "print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_train, rf_train_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_train, rf_train_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_train, rf_train_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_train, rf_train_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_train, rf_train_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_train, rf_train_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_train, rf_train_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_train, rf_train_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_train, rf_train_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Random Forest Trigram Performance on Testing Set:\")\n",
    "#print(\"Paramters: \", rf.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y3_test, rf_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y3_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y3_test, rf_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y3_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y3_test, rf_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y3_test, rf_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y3_test, rf_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y3_test, rf_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y3_test, rf_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LDA Topics as features to ML models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/amanuel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#LDA topics as features to ML\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import pickle\n",
    "import gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "#import spacy\n",
    "import pandas as pd\n",
    "import nltk; nltk.download('stopwords')\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import re\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#list of stopwords\n",
    "with open('terrier-stop.txt') as f:\n",
    "    stop_words = f.read().splitlines()\n",
    "    \n",
    "stop_words.extend(['come','order','try','go','get','make','drink','plate','dish','restaurant','place',\n",
    "                  'would','really','like','great','service','came','got'])\n",
    "\n",
    "\n",
    "def strip_newline(series):\n",
    "    return [str(review).replace('\\n','') for review in series]\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "    \n",
    "def get_corpus(df):\n",
    "    df['text'] = strip_newline(df.text)\n",
    "    words = list(sent_to_words(df.text))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[review] for review in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    return corpus, id2word, bigram\n",
    "\n",
    "rev_train = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pain_Relevance</th>\n",
       "      <th>Pain_Change</th>\n",
       "      <th>Raw_Text</th>\n",
       "      <th>Str_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "      <td>patient . arrived vdh pain management ivf awai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "      <td>patient continue pain control regimen 0/10 pain .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>not sure</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "      <td>patient continue take pain medication without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patient received chc via wheelchair room air ....</td>\n",
       "      <td>patient received chc via wheelchair room air ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>increase</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "      <td>patient remains 8-10/10 pain . pca initiated .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pain_Relevance Pain_Change  \\\n",
       "0               1    increase   \n",
       "1               1    not sure   \n",
       "2               1    not sure   \n",
       "3               0         NaN   \n",
       "4               1    increase   \n",
       "\n",
       "                                            Raw_Text  \\\n",
       "0  patient . arrived vdh pain management ivf awai...   \n",
       "1  patient continue pain control regimen 0/10 pain .   \n",
       "2  patient continue take pain medication without ...   \n",
       "3  patient received chc via wheelchair room air ....   \n",
       "4     patient remains 8-10/10 pain . pca initiated .   \n",
       "\n",
       "                                            Str_Text  \n",
       "0  patient . arrived vdh pain management ivf awai...  \n",
       "1  patient continue pain control regimen 0/10 pain .  \n",
       "2  patient continue take pain medication without ...  \n",
       "3  patient received chc via wheelchair room air ....  \n",
       "4     patient remains 8-10/10 pain . pca initiated .  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_train = rev_train.rename(columns={\"Str_Text\": \"text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus4, train_id2word4, bigram_train4 = get_corpus(rev_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigram_train4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train4 = gensim.models.ldamulticore.LdaMulticore(\n",
    "                           corpus=train_corpus4,\n",
    "                           num_topics=2,\n",
    "                           id2word=train_id2word4,\n",
    "                           chunksize=100,\n",
    "                           workers=7, # Num. Processing Cores - 1\n",
    "                           passes=50,\n",
    "                           eval_every = 1,\n",
    "                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.172*\"medication\" + 0.145*\"satisfied\" + 0.141*\"intervention\" + 0.141*\"emar\" + 0.073*\"pca\" + 0.051*\"collaborate\" + 0.040*\"shift\" + 0.034*\"toradol\" + 0.032*\"admission\" + 0.031*\"time\"'),\n",
       " (1,\n",
       "  '0.146*\"regimen\" + 0.096*\"satisfaction\" + 0.095*\"knowledge\" + 0.071*\"cope_supported\" + 0.052*\"deficit\" + 0.051*\"state_carry\" + 0.051*\"method\" + 0.045*\"met_continue\" + 0.043*\"expression_comfortable\" + 0.042*\"alteration_comfort\"')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train4.print_topics(2,num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(rev_train)):\n",
    "    top_topics = lda_train4.get_document_topics(train_corpus4[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(2)]\n",
    "    topic_vec.extend([len(rev_train.iloc[i].text)]) # length of a clinical note\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26196265, 0.7380373, 49]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_array = csr_matrix(x1, dtype=np.int8).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  2.        ,  0.        ,  0.        ,\n",
       "        0.26196265,  0.73803729, 49.        ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((x1_array[1], X[1]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cumulative = list()\n",
    "for i,j in zip(x1_array,X):\n",
    "    X_cumulative.append(np.concatenate((i, j), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cum_train, x_cum_test, y1_train, y1_test = train_test_split(X_cumulative, y, test_size=test_ratio, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifiers with concatenated LDA topics and n-grams as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance on Testing Set:\n",
      "Macro Precision Score: 0.475\n",
      "Weighted Precision Score: 0.902\n",
      "Macro Recall Score: 0.500\n",
      "Weighted Recall Score: 0.950\n",
      "Micro F1 Score: 0.950\n",
      "Macro F1 Score: 0.487\n",
      "Weighted F1 Score: 0.926\n",
      "Confusion Matrix: \n",
      " [[  0   6]\n",
      " [  0 114]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amanuel/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Train a Logistic Regression Classifier with concatenated LDA topics and n-grams as features\n",
    "param_grid_lr = {\n",
    "         'C': [1.0, 1e2, 1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "         'solver': ('newton-cg', 'lbfgs', 'sag', 'saga')\n",
    "          }\n",
    "lr = GridSearchCV(LogisticRegression(random_state=42, multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "#lr = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=40000), param_grid_lr, cv=5)\n",
    "lr = lr.fit(x_cum_train, y1_train)\n",
    "lr_train_pred = lr.predict(x_cum_train)\n",
    "lr_test_pred = lr.predict(x_cum_test)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", lr.best_params_)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, lr_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, lr_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, lr_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, lr_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, lr_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, lr_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, lr_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, lr_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance on Testing Set:\n",
      "Macro Precision Score: 0.773\n",
      "Weighted Precision Score: 0.977\n",
      "Macro Recall Score: 0.978\n",
      "Weighted Recall Score: 0.958\n",
      "Micro F1 Score: 0.958\n",
      "Macro F1 Score: 0.842\n",
      "Weighted F1 Score: 0.964\n",
      "Confusion Matrix: \n",
      " [[  6   0]\n",
      " [  5 109]]\n"
     ]
    }
   ],
   "source": [
    "#Train a Decision Tree Classifier with concatenated LDA topics and n-grams as features\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "#dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(x_cum_train, y1_train)\n",
    "dt_train_pred = dt.predict(x_cum_train)\n",
    "dt_test_pred = dt.predict(x_cum_test)\n",
    "\n",
    "\n",
    "print(\"Decision Tree Performance on Testing Set:\")\n",
    "#print(\"Parameters: \", dt.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, dt_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, dt_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, dt_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, dt_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, dt_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, dt_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, dt_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Performance on Testing Set:\n",
      "Macro Precision Score: 0.475\n",
      "Weighted Precision Score: 0.902\n",
      "Macro Recall Score: 0.500\n",
      "Weighted Recall Score: 0.950\n",
      "Micro F1 Score: 0.950\n",
      "Macro F1 Score: 0.487\n",
      "Weighted F1 Score: 0.926\n",
      "Confusion Matrix: \n",
      " [[  0   6]\n",
      " [  0 114]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amanuel/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Train a Random Forest Classifier with concatenated LDA topics and n-grams as features\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42)\n",
    "#rf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rf = rf.fit(x_cum_train, y1_train)\n",
    "rf_train_pred = rf.predict(x_cum_train)\n",
    "rf_test_pred = rf.predict(x_cum_test)\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Performance on Testing Set:\")\n",
    "#print(\"Paramters: \", rf.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, rf_test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, rf_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, rf_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, rf_test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, rf_test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, rf_test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, rf_test_pred, average='weighted'))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, rf_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Unigram Performance on Test Set:\n",
      "Macro Precision Score: 0.737\n",
      "Weighted Precision Score: 0.950\n",
      "Macro Recall Score: 0.737\n",
      "Weighted Recall Score: 0.950\n",
      "Micro F1 Score: 0.950\n",
      "Macro F1 Score: 0.737\n",
      "Weighted F1 Score: 0.950\n",
      "Confusion Matrix: \n",
      " [[  3   3]\n",
      " [  3 111]]\n"
     ]
    }
   ],
   "source": [
    "#Train an MLP Classifier with concatenated LDA topics and n-grams as features\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000, random_state=42)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(5,5), max_iter=10000)\n",
    "mlp = mlp.fit(x_cum_train, y1_train)\n",
    "train_pred = mlp.predict(x_cum_train)\n",
    "test_pred = mlp.predict(x_cum_test)\n",
    "\n",
    "\n",
    "\n",
    "#print()\n",
    "\n",
    "print('Neural Network Unigram Performance on Test Set:')\n",
    "#print('Parameters: ', mlp.get_params)\n",
    "#print('Accuracy Score: %.3f' % metrics.accuracy_score(y1_test, test_pred))\n",
    "print('Macro Precision Score: %.3f' % metrics.precision_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y1_test, test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y1_test, test_pred, average='weighted'))\n",
    "print('Micro F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='micro'))\n",
    "print('Macro F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='macro'))\n",
    "print('Weighted F1 Score: %.3f' % metrics.f1_score(y1_test, test_pred, average='weighted'))\n",
    "#print('Mean Accuracy Score: %.3f' % mlp.score(x_test, y_test))\n",
    "print('Confusion Matrix: \\n', metrics.confusion_matrix(y1_test, test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "rev_train['Pain_Relevance'] = encoder.fit_transform(data['Pain_Relevance'].astype(str))\n",
    "\n",
    "#y = data[['Pain_Relevance']]\n",
    "y = np.array(rev_train.Pain_Relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML classification using only LDA topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.756 +- 0.042\n",
      "Logisitic Regression SGD Val f1: 0.755 +- 0.141\n",
      "SVM Huber Val f1: 0.977 +- 0.012\n",
      "Decision Tree Val f1: 0.972 +- 0.013\n",
      "MLP Val f1: 0.972 +- 0.013\n",
      "Random Forest Val f1: 0.978 +- 0.011\n",
      "\n",
      "\n",
      "Logistic Regression Val precision: 0.991 +- 0.010\n",
      "Logisitic Regression SGD Val precision: 0.973 +- 0.034\n",
      "SVM Huber Val precision: 0.955 +- 0.023\n",
      "Decision Tree Val precision: 0.974 +- 0.017\n",
      "MLP Val precision: 0.974 +- 0.017\n",
      "Random Forest Val precision: 0.957 +- 0.022\n",
      "\n",
      "\n",
      "Logistic Regression Val recall: 0.613 +- 0.054\n",
      "Logisitic Regression SGD Val recall: 0.651 +- 0.223\n",
      "SVM Huber Val recall: 1.000 +- 0.000\n",
      "Decision Tree Val recall: 0.971 +- 0.010\n",
      "MLP Val recall: 0.971 +- 0.010\n",
      "Random Forest Val recall: 1.000 +- 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, dt_test_pred, average='weighted'))\\nprint('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, dt_test_pred, average='macro'))\\nprint('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, dt_test_pred, average='weighted'))\\n\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For ML classification built from LDA topics alone\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1, cv_dt_f1, cv_mlp_f1, cv_rf_f1, cv_svm_f1  = [], [], [], [], [], [], []\n",
    "cv_lr_precision, cv_lrsgd_precision, cv_svcsgd_precision, cv_dt_precision, cv_mlp_precision, cv_rf_precision, cv_svm_precision = [], [], [], [],[], [], []\n",
    "cv_lr_recall, cv_lrsgd_recall, cv_svcsgd_recall, cv_dt_recall, cv_mlp_recall, cv_rf_recall, cv_svm_recall = [], [], [], [],[], [],[]\n",
    "\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_lr_precision.append(precision_score(y_val, y_pred, average='binary'))\n",
    "    cv_lr_recall.append(recall_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    \n",
    "    # Logistic Regression Mini-Batch SGD\n",
    "    sgd = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_lrsgd_precision.append(precision_score(y_val, y_pred, average='binary'))\n",
    "    cv_lrsgd_recall.append(recall_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        alpha=20,\n",
    "        loss='modified_huber',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_svcsgd_precision.append(precision_score(y_val, y_pred, average='binary'))\n",
    "    cv_svcsgd_recall.append(recall_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # Decision tree classifier\n",
    "    dt = DecisionTreeClassifier(random_state=42).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = dt.predict(X_val_scale)\n",
    "    cv_dt_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_dt_precision.append(precision_score(y_val, y_pred, average='binary'))\n",
    "    cv_dt_recall.append(recall_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    # MLP Classifier\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(5,5), max_iter=10000, random_state=42).fit(X_train_scale, y_train)\n",
    "    y_pred = dt.predict(X_val_scale)\n",
    "    cv_mlp_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_mlp_precision.append(precision_score(y_val, y_pred, average='binary'))\n",
    "    cv_mlp_recall.append(recall_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "    #Random Forest Classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_val_scale)\n",
    "    cv_rf_f1.append(f1_score(y_val, y_pred, average='binary'))\n",
    "    cv_rf_precision.append(precision_score(y_val, y_pred, average='binary'))\n",
    "    cv_rf_recall.append(recall_score(y_val, y_pred, average='binary'))\n",
    "    \n",
    "\n",
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')\n",
    "print(f'Decision Tree Val f1: {np.mean(cv_dt_f1):.3f} +- {np.std(cv_dt_f1):.3f}')\n",
    "print(f'MLP Val f1: {np.mean(cv_mlp_f1):.3f} +- {np.std(cv_mlp_f1):.3f}')\n",
    "print(f'Random Forest Val f1: {np.mean(cv_rf_f1):.3f} +- {np.std(cv_rf_f1):.3f}')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(f'Logistic Regression Val precision: {np.mean(cv_lr_precision):.3f} +- {np.std(cv_lr_precision):.3f}')\n",
    "print(f'Logisitic Regression SGD Val precision: {np.mean(cv_lrsgd_precision):.3f} +- {np.std(cv_lrsgd_precision):.3f}')\n",
    "print(f'SVM Huber Val precision: {np.mean(cv_svcsgd_precision):.3f} +- {np.std(cv_svcsgd_precision):.3f}')\n",
    "print(f'Decision Tree Val precision: {np.mean(cv_dt_precision):.3f} +- {np.std(cv_dt_precision):.3f}')\n",
    "print(f'MLP Val precision: {np.mean(cv_mlp_precision):.3f} +- {np.std(cv_mlp_precision):.3f}')\n",
    "print(f'Random Forest Val precision: {np.mean(cv_rf_precision):.3f} +- {np.std(cv_rf_precision):.3f}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Logistic Regression Val recall: {np.mean(cv_lr_recall):.3f} +- {np.std(cv_lr_recall):.3f}')\n",
    "print(f'Logisitic Regression SGD Val recall: {np.mean(cv_lrsgd_recall):.3f} +- {np.std(cv_lrsgd_recall):.3f}')\n",
    "print(f'SVM Huber Val recall: {np.mean(cv_svcsgd_recall):.3f} +- {np.std(cv_svcsgd_recall):.3f}')\n",
    "print(f'Decision Tree Val recall: {np.mean(cv_dt_recall):.3f} +- {np.std(cv_dt_recall):.3f}')\n",
    "print(f'MLP Val recall: {np.mean(cv_mlp_recall):.3f} +- {np.std(cv_mlp_recall):.3f}')\n",
    "print(f'Random Forest Val recall: {np.mean(cv_rf_recall):.3f} +- {np.std(cv_rf_recall):.3f}')\n",
    "\n",
    "\n",
    "'''\n",
    "print('Weighted Precision Score: %.3f' % metrics.precision_score(y2_test, dt_test_pred, average='weighted'))\n",
    "print('Macro Recall Score: %.3f' % metrics.recall_score(y2_test, dt_test_pred, average='macro'))\n",
    "print('Weighted Recall Score: %.3f' % metrics.recall_score(y2_test, dt_test_pred, average='weighted'))\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
